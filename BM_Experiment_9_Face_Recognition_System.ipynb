{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rey/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64  \n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataset(path):\n",
    "    filePaths = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    name = ''\n",
    "\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        if count != 0:\n",
    "            x = dirname.split('/')[-1]\n",
    "            index = x.rindex('_name_')\n",
    "            name = x[index+6:].replace(' ','')\n",
    "        for filename in filenames:\n",
    "            full_path = os.path.join(dirname, filename)\n",
    "            filePaths.append(full_path)\n",
    "            y.append(name)\n",
    "        \n",
    "        count += 1\n",
    "    return filePaths, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hispanic_path = 'Selfies_ID_Images_dataset/11_sets_Hispanics'  \n",
    "caucasian_path = 'Selfies_ID_Images_dataset/18_sets_Caucasians'  \n",
    "\n",
    "hispanic_filePaths, hispanic_labels = prepareDataset(hispanic_path)\n",
    "caucasian_filePaths, caucasian_labels = prepareDataset(caucasian_path)\n",
    "\n",
    "\n",
    "filePaths = hispanic_filePaths + caucasian_filePaths\n",
    "y_labels = hispanic_labels + caucasian_labels  \n",
    "\n",
    "# Load and preprocess the images\n",
    "for i, filePath in enumerate(filePaths):\n",
    "    if not filePath.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        print(f\"Skipping non-image file: {filePath}\")\n",
    "        continue\n",
    "    try:\n",
    "        pil_image = Image.open(filePath).convert('RGB')\n",
    "        image = np.array(pil_image)\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        data.append(image)\n",
    "        labels.append(y_labels[i])\n",
    "    except (IOError, OSError) as e:\n",
    "        print(f\"Warning: Could not read image from {filePath} - {e}\")\n",
    "#\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Count:  11\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "number_of_classes = labels.shape[1]\n",
    "print(\"Classes Count: \",number_of_classes)\n",
    "np.save('label_classes.npy', lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(number_of_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=1e-4), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 49ms/step - loss: 2.4829 - accuracy: 0.1091\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 2.4058 - accuracy: 0.1333\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 2.3535 - accuracy: 0.1273\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 2.3633 - accuracy: 0.1152\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 2.2697 - accuracy: 0.2242\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 2.2876 - accuracy: 0.2000\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.2436 - accuracy: 0.2364\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 2.1919 - accuracy: 0.2303\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 2.1745 - accuracy: 0.2788\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 2.1265 - accuracy: 0.3091\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.0813 - accuracy: 0.3030\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.1145 - accuracy: 0.2788\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 2.0350 - accuracy: 0.2909\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 2.0254 - accuracy: 0.3394\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 1.9530 - accuracy: 0.3818\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 1.8908 - accuracy: 0.3939\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.9500 - accuracy: 0.3758\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.8605 - accuracy: 0.3515\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.8218 - accuracy: 0.3879\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 1.7284 - accuracy: 0.3818\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 1.6988 - accuracy: 0.4182\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.7439 - accuracy: 0.4000\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.6689 - accuracy: 0.4545\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.6896 - accuracy: 0.4485\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.5328 - accuracy: 0.5212\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.5420 - accuracy: 0.5212\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 1.4338 - accuracy: 0.5697\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.4009 - accuracy: 0.5394\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 1.4779 - accuracy: 0.4909\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 1.3478 - accuracy: 0.5333\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 1.3551 - accuracy: 0.5758\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 1.3226 - accuracy: 0.5818\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 1.1978 - accuracy: 0.6545\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 1.2282 - accuracy: 0.5939\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 1.2740 - accuracy: 0.6000\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 1.2179 - accuracy: 0.6242\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 1.0906 - accuracy: 0.6545\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 1.0826 - accuracy: 0.6606\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.0667 - accuracy: 0.6242\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 1.0409 - accuracy: 0.6303\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.9406 - accuracy: 0.6970\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.9052 - accuracy: 0.7273\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.9190 - accuracy: 0.7091\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.8304 - accuracy: 0.7394\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.8244 - accuracy: 0.7333\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.7492 - accuracy: 0.7333\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.7879 - accuracy: 0.7333\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.6873 - accuracy: 0.7879\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.7271 - accuracy: 0.7758\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.6884 - accuracy: 0.7939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rey/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.fit(data, labels, epochs=50, batch_size=32)\n",
    "model.save('Models/face_recognition_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Alejandra       1.00      0.93      0.97        15\n",
      "       Bruno       1.00      0.60      0.75        15\n",
      "      Daiane       0.74      0.93      0.82        15\n",
      "    Fernanda       0.87      0.87      0.87        15\n",
      "     Gabriel       1.00      0.93      0.97        15\n",
      "     Juliana       0.92      0.73      0.81        15\n",
      "        Luis       0.83      1.00      0.91        15\n",
      "     Matheus       0.75      1.00      0.86        15\n",
      "     Rayanne       0.93      0.93      0.93        15\n",
      "     RoÌ‚mulo       0.74      0.93      0.82        15\n",
      "     Weslley       1.00      0.67      0.80        15\n",
      "\n",
      "    accuracy                           0.87       165\n",
      "   macro avg       0.89      0.87      0.86       165\n",
      "weighted avg       0.89      0.87      0.86       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Models/face_recognition_model.h5')\n",
    "predictions = model.predict(data)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(labels, axis=1)\n",
    "lb.classes_ = np.load('label_classes.npy')\n",
    "report = classification_report(true_classes, predicted_classes, target_names=lb.classes_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[14  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  9  2  0  0  1  1  0  1  1  0]\n",
      " [ 0  0 14  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 13  0  0  1  0  0  1  0]\n",
      " [ 0  0  1  0 14  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 11  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 15  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 14  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0 14  0]\n",
      " [ 0  0  1  1  0  0  1  1  0  1 10]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
